{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bfaa64-78ac-4880-9329-8d4ae4c57d82",
   "metadata": {},
   "source": [
    "# Manual PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d47e04-5461-4988-8591-84fad315e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA After PCA: \n",
      "[0.007583252839687594, 0.00036374751548070964]\n",
      "[0.007160983540029816, 0.00034349243341217825]\n",
      "[0.006985037998505742, 0.00033505281588362354]\n",
      "[0.0053663390164842605, 0.0002574083346209198]\n",
      "[0.005331149908179445, 0.0002557204111152089]\n"
     ]
    }
   ],
   "source": [
    "def read_arff(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data_section = False\n",
    "    attributes = []\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip().lower()\n",
    "\n",
    "        if line.startswith('@attribute'):\n",
    "            parts = line.split()\n",
    "            attr_name = parts[1].strip()\n",
    "            attr_type = parts[2].strip().lower()\n",
    "\n",
    "            if attr_type.startswith('{'):\n",
    "                attr_values = [value.strip('{},') for value in parts[3:]]\n",
    "                attributes.append((attr_name, 'nominal', attr_values))\n",
    "            else:\n",
    "                attributes.append((attr_name, 'numeric', []))\n",
    "        elif line == '@data':\n",
    "            data_section = True\n",
    "        elif data_section:\n",
    "            instance_values = [value.strip() for value in line.split(',')]\n",
    "            data.append(instance_values)\n",
    "\n",
    "    return attributes, data\n",
    "\n",
    "def mean_centering(data):\n",
    "    num_samples = len(data)\n",
    "    num_features = len(data[0])\n",
    "    mean_vector = [sum(data[i][j] for i in range(num_samples)) / num_samples for j in range(num_features)]\n",
    "    centered_data = [[data[i][j] - mean_vector[j] for j in range(num_features)] for i in range(num_samples)]\n",
    "    return centered_data, mean_vector\n",
    "\n",
    "def transpose_matrix(matrix):\n",
    "    return [[matrix[j][i] for j in range(len(matrix))] for i in range(len(matrix[0]))]\n",
    "\n",
    "def multiply_matrices(matrix_a, matrix_b):\n",
    "    return [[sum(matrix_a[i][k] * matrix_b[k][j] for k in range(len(matrix_b[0])))\n",
    "             for j in range(len(matrix_b[0]))] for i in range(len(matrix_a))]\n",
    "\n",
    "def eigen_decomposition(matrix):\n",
    "    num_rows = len(matrix)\n",
    "    num_columns = len(matrix[0])\n",
    "    identity_matrix = [[0 if i != j else 1 for j in range(num_columns)] for i in range(num_rows)]\n",
    "    eigenvectors = [row.copy() for row in matrix]\n",
    "    eigenvalues = [0] * num_columns\n",
    "\n",
    "    num_iterations = 1000\n",
    "    for _ in range(num_iterations):\n",
    "        eigenvectors = multiply_matrices(matrix, eigenvectors)\n",
    "        norm = max([abs(eigenvectors[i][j]) for i in range(num_rows) for j in range(num_columns)])\n",
    "        eigenvectors = [[eigenvectors[i][j] / norm for j in range(num_columns)] for i in range(num_rows)]\n",
    "        eigenvalues = [eigenvectors[i][i] for i in range(num_columns)]\n",
    "        if abs(norm - 1.0) < 1e-6:\n",
    "            break\n",
    "\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def pca_manual(data, num_components):\n",
    "    centered_data, mean_vector = mean_centering(data)\n",
    "    transposed_data = transpose_matrix(centered_data)\n",
    "    covariance_matrix = multiply_matrices(transposed_data, centered_data)\n",
    "    covariance_matrix = [[element / (len(centered_data) - 1) for element in row] for row in covariance_matrix]\n",
    "    eigenvalues, eigenvectors = eigen_decomposition(covariance_matrix)\n",
    "    sorted_indices = sorted(range(len(eigenvalues)), key=lambda k: eigenvalues[k], reverse=True)\n",
    "    eigenvectors = [eigenvectors[i] for i in sorted_indices]\n",
    "    selected_eigenvectors = eigenvectors[:num_components]\n",
    "    transformed_data = multiply_matrices(centered_data, transpose_matrix(selected_eigenvectors))\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "arff_file_paths = [\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2017 Q1.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2017 Q2.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2017 Q3.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2017 Q4.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2017.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2018 Q1.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2018 Q2.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2018 Q3.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2018 Q4.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2018.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2019 Q1.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2019 Q2.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2019 Q3.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2019 Q4.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2019.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2020 Q1.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2020 Q2.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2020 Q3.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2020 Q4.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2020.arff',\n",
    "    r'/Users/ernest/Desktop/School/3101-Discrete/prefis/Discrete-Structures-III-Pre-Finals/V4data/2021 Q1.arff'\n",
    "]\n",
    "\n",
    "def read_arff(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data_section = False\n",
    "    attributes = []\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip().lower()\n",
    "\n",
    "        if line.startswith('@attribute'):\n",
    "            parts = line.split()\n",
    "            attr_name = parts[1].strip()\n",
    "            attr_type = parts[2].strip().lower()\n",
    "\n",
    "            if attr_type.startswith('{'):\n",
    "                attr_values = [value.strip('{},') for value in parts[3:]]\n",
    "                attributes.append((attr_name, 'nominal', attr_values))\n",
    "            else:\n",
    "                attributes.append((attr_name, 'numeric', []))\n",
    "        elif line == '@data':\n",
    "            data_section = True\n",
    "        elif data_section:\n",
    "            instance_values = [value.strip() for value in line.split(',')]\n",
    "            data.append(instance_values)\n",
    "\n",
    "    return attributes, data\n",
    "\n",
    "def nominal_mapping(data, attributes):\n",
    "    for i in range(len(attributes)):\n",
    "        _, attr_type, attr_values = attributes[i]\n",
    "\n",
    "        if attr_type == 'nominal':\n",
    "            nominal_mapping = {value: index for index, value in enumerate(attr_values)}\n",
    "            for row in data:\n",
    "                row[i] = nominal_mapping.get(row[i])\n",
    "\n",
    "def process_numeric_values(data):\n",
    "    for row in data:\n",
    "        for i in range(len(row)):\n",
    "            if row[i] is not None and row[i] != '?':  # Add a check for None or other missing value indicators\n",
    "                try:\n",
    "                    row[i] = float(row[i])\n",
    "                except ValueError:\n",
    "                    row[i] = 0\n",
    "            else:\n",
    "                row[i] = 0  # Handle missing values by assigning a default (you can modify this as needed)\n",
    "\n",
    "num_components = 2\n",
    "combined_data = []\n",
    "\n",
    "for file_path in arff_file_paths:\n",
    "    attributes, arff_data = read_arff(file_path)\n",
    "    nominal_mapping(arff_data, attributes)\n",
    "    process_numeric_values(arff_data)\n",
    "    \n",
    "    for row in arff_data:\n",
    "        combined_data.append(row)\n",
    "        \n",
    "    \n",
    "transformed_data = pca_manual(combined_data, num_components)\n",
    "\n",
    "# Edit how many lines to print\n",
    "LINES_TO_PRINT = 5\n",
    "\n",
    "print(\"DATA After PCA: \")\n",
    "for i in range(LINES_TO_PRINT):    \n",
    "    print(transformed_data[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94f1aa-e992-490e-ac20-6db89f5d52ac",
   "metadata": {},
   "source": [
    "# SKLearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf0837f-1c82-404b-b822-5fd237a92fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (scikit-learn): [-1215380.0870013    306925.85405383]\n",
      "Transformed Data (scikit-learn): [-1215007.4288357    117299.35771622]\n",
      "Transformed Data (scikit-learn): [-1214985.09815708   -15965.64872126]\n",
      "Transformed Data (scikit-learn): [-1.21509913e+06  1.13160130e+03]\n",
      "Transformed Data (scikit-learn): [-1215378.24192985   -20915.62441121]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'combined_data' is your data matrix\n",
    "combined_data_np = np.array(combined_data)\n",
    "\n",
    "# Specify the number of components\n",
    "num_components = 2\n",
    "\n",
    "# Perform PCA using scikit-learn\n",
    "pca_sklearn = PCA(n_components=num_components)\n",
    "transformed_data_sklearn = pca_sklearn.fit_transform(combined_data_np)\n",
    "\n",
    "LINES_TO_PRINT = 5\n",
    "\n",
    "for i in range(LINES_TO_PRINT):\n",
    "    print(\"Transformed Data (scikit-learn):\", transformed_data_sklearn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b48d9-129d-4d21-a534-a400fb737824",
   "metadata": {},
   "source": [
    "After preprocessing the data, including handling missing values and converting nominal attributes, I calculated the covariance matrix and performed eigen decomposition. I then compared the results with scikit-learn's PCA, making sure to check for consistency in steps like sorting eigenvalues and eigenvectors. The comparison revealed that my custom implementation and scikit-learn's results were similar, indicating that my PCA implementation is likely accurate. However, discrepancies could arise from differences in handling floating-point precision or default parameters.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26326d2-1f5c-4c24-be21-25089ae736f3",
   "metadata": {},
   "source": [
    "# Manual SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496ba75-0ea0-462f-a79c-88304ebed86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vector1, vector2):\n",
    "    return sum(x * y for x, y in zip(vector1, vector2))\n",
    "\n",
    "def transpose_matrix(matrix):\n",
    "    return [[matrix[j][i] for j in range(len(matrix))] for i in range(len(matrix[0]))]\n",
    "\n",
    "def matrix_multiply(matrix1, matrix2):\n",
    "    return [[dot_product(row, col) for col in transpose_matrix(matrix2)] for row in matrix1]\n",
    "\n",
    "def vector_normalize(vector):\n",
    "    magnitude = dot_product(vector, vector) ** 0.5\n",
    "    return [val / magnitude for val in vector]\n",
    "\n",
    "def svd_from_scratch(matrix):\n",
    "    transposed_matrix = transpose_matrix(matrix)\n",
    "    covariance_matrix = matrix_multiply(transposed_matrix, matrix)\n",
    "    return U, singular_values, V\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05d59a-5dba-45f3-a609-49388a4fc39f",
   "metadata": {},
   "source": [
    "# SKlearn SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d689844-20c0-442b-96cd-d7935f74d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "num_components = 2\n",
    "\n",
    "# Create and fit the TruncatedSVD model\n",
    "svd_model = TruncatedSVD(n_components=num_components)\n",
    "svd_result = svd_model.fit_transform(combined_data)\n",
    "\n",
    "# Access the U, singular values, and V matrices\n",
    "U_sklearn = svd_result\n",
    "S_sklearn = svd_model.singular_values_\n",
    "V_sklearn = svd_model.components_\n",
    "\n",
    "print(\"Matrix U (sklearn):\", U_sklearn)\n",
    "print(\"Singular Values (sklearn):\", S_sklearn)\n",
    "print(\"Matrix V (sklearn):\", V_sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78c9c5-af6f-4b56-9f62-6dfeb0a2b5b0",
   "metadata": {},
   "source": [
    "The difference between the manual SVD and the SKlearn SVD "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
